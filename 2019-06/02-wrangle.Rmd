---
title: "Wrangle Democratic Candidate 2019 Data"
author: "John Doe"
output: github_document
---

```{r setup, include=FALSE}
# create image folder ----
if (!file.exists("figs/")) {
    dir.create("figs/")
}
# create data folder ----
if (!file.exists("data/")) {
    dir.create("data/")
}
knitr::opts_chunk$set(
    echo = TRUE, # show all code
    eval = TRUE,
    message = FALSE, 
    comment = "#> ",
    warning = TRUE,
    tidy = FALSE, # cleaner code printing
    size = "small",
    fig.path = "figs/") # smaller code
knitr::opts_knit$set(
    width = 78)
base::options(tibble.print_max = 25,
              tibble.width = 78)
```

# Motivation 

This document describes the steps used to wrangle the candidate data.


## Packages

The Google search trends are accessible via the [gtrendsR](https://github.com/PMassicotte/gtrendsR) package. This and other packages are in the `00-packages.R` script. We load these packages in the code chunk below. 

```{r 00-packages.R, eval=TRUE}
# fs::dir_tree(".")
library(gtrendsR)
library(maps)
library(ggplot2)
library(lettercase)
library(viridis)
library(pals)
library(scico)
library(ggrepel)
library(tidyverse)
library(skimr)
```

## Import data

```{r import-data}
# fs::dir_tree(path = "code", recurse = FALSE)
source("code/01-import.R")
# ls()
```

### Some R programming

Your code will always be communicating to at least two audiences: your computer, and your future self. Be nice to both of them!

Things like the pipe `%>%` in R can help with clarity. It takes code written like this:

```r
outer_function(inner_function(Data_X), Data_Y)
```

And makes it look like this:

```r
Data_X %>% # do this 
   inner_function() %>% # then do this
   outer_function(Data_Y)
```

## Wrangle the Wikipedia tables

This table needed new names, two rows removed from the top of the table, and a numeric `airtime` variable. 

```{r wrangle-wikipedia}
# wrangle wikipedia data night 1 --------
WikiDemAirTime01 <- WikiDemAirTime01Raw %>% 
  magrittr::set_colnames(value = c("candidate", "airtime_night1"))

WikiDemAirTime01 <- WikiDemAirTime01 %>% 
  dplyr::filter(candidate %nin% c("Night one airtime", "Candidate") & 
         airtime_night1  %nin% c("Night one airtime", "Airtime (min.)[58]")) %>% 
  dplyr::mutate(airtime_night1 = as.numeric(airtime_night1))

# wrangle wikipedia data night 2 --------
WikiDemAirTime02 <- WikiDemAirTime02Raw %>% 
  magrittr::set_colnames(value = c("candidate", "airtime_night2")) 
WikiDemAirTime02 <- WikiDemAirTime02 %>% 
    dplyr::filter(candidate %nin% c("Night two airtime", "Candidate") & 
         airtime_night2  %nin% c("Night one airtime", "Airtime (min.)[58]")) %>%
  dplyr::mutate(airtime_night2 = as.numeric(airtime_night2))

# wrangle polling criterion data ------------------------------------------
# create list from names
# dput(WikiPollCriterionRaw[ 1:11, 1])
cand_names_wiki <- c("Warren[note 2]", 
                     "O'Rourke[note 2]", 
                     "Booker[note 2]", 
                     "Klobuchar[note 2]", 
                     "Castro[note 2]", 
                     "Gabbard", 
                     "Ryan", 
                     "Inslee", 
                     "de Blasio", 
                     "Delaney")
# subset with list
WikiPollCriterion <- WikiPollCriterionRaw %>% 
  dplyr::filter(`Candidates drawn for the June 26 debate` %in% cand_names_wiki)
# clean up
WikiPollCriterion <- WikiPollCriterion %>%
  # new names
  magrittr::set_names(value = c("candidates", "polling_crit_perc")) %>% 
  # remove table junk from wiki
  dplyr::mutate(candidates = stringr::str_remove_all(string = candidates, 
                                                 pattern = "\\[note 2\\]")) %>% 
  # split up counts and percents
  tidyr::separate(col = polling_crit_perc, 
                  into = c("poll_perc", "poll_count"), 
                  sep = " ") %>% 
  # remove more junk from wiki
  dplyr::mutate(poll_count = stringr::str_remove_all(string = poll_count, 
                                                 pattern = "\\("),
                # convert to numeric
                poll_count = as.numeric(poll_count),
                # remove % symbol
                poll_perc = stringr::str_remove_all(string = poll_perc, 
                                                 pattern = "\\%"),
                # convert to numeric
                poll_perc = as.numeric(poll_perc),
                # get actual percent
                poll_perc = poll_perc*0.01)
```

## Wrangle the Google data 

The exported data is a `list`, so the `inerest_over_time` table is converted to a tibble for easier manipulation.

We then make `hits` numeric, and join the two tibbles together. 

```{r wrangle-google-trend-interest-over-time}
# wrangle Google trend data -----------------------------------------------
# convert Dems2020Group1 to tibble
GTrendDems2020Group1IOT <- GTrendDems2020Night1G1$interest_over_time %>% 
  as_tibble()

# convert Dems2020Group2 to tibble
GTrendDems2020Group2IOT <- GTrendDems2020Night1G2$interest_over_time %>% 
  as_tibble()

# create numeric hits 
GTrendDems2020Group1IOT <- GTrendDems2020Group1IOT %>% 
  dplyr::mutate(hits = as.numeric(hits)) 
GTrendDems2020Group2IOT <- GTrendDems2020Group2IOT %>%
  dplyr::mutate(hits = as.numeric(hits)) 

# bind -----------------------------------------------
GTrendDems2020Debate01IOT <- bind_rows(GTrendDems2020Group1IOT, 
          GTrendDems2020Group2IOT,
          .id = "data") 
```

Create gender

This creates the `gender` variable. 

```{r gender}
# gender ------------------------------------------------------------------
GTrendDems2020Debate01IOT <- GTrendDems2020Debate01IOT %>% 
  dplyr::mutate(gender = case_when(
    stringr::str_detect(keyword, "Elizabeth Warren") ~ "Women", 
    stringr::str_detect(keyword, "Amy Klobuchar") ~ "Women",
    stringr::str_detect(keyword, "Tulsi Gabbard") ~ "Women",
    TRUE ~ "Men"))
```

Reduce to distinct.

```{r distinct-GTrendDems2020Debate01IOT}
# get distinct
GTrendDems2020Debate01IOT <- GTrendDems2020Debate01IOT %>% distinct()
# GTrendDems2020Debate01IOT %>% glimpse(78)
```

Join to wikipedia table.

```{r join-to-wiki-data}
# join Gtrend with wikipedia data --------------------------------------------
# sort alphabetically, join on id
WikiDemAirTime01 <- WikiDemAirTime01 %>% dplyr::arrange(desc(candidate))
# add id
WikiDemAirTime01 <- WikiDemAirTime01 %>% 
  mutate(candidate_id = row_number())
# WikiDemAirTime01
GTrendDems2020Debate01IOT <- GTrendDems2020Debate01IOT %>% 
  dplyr::mutate(candidate_id = case_when(
    stringr::str_detect(string = keyword, pattern = "Warren") ~ 1,
    stringr::str_detect(string = keyword, pattern = "Ryan") ~ 2,
    stringr::str_detect(string = keyword, pattern = "Beto") ~ 3,
    stringr::str_detect(string = keyword, pattern = "Klobuchar") ~ 4,
    stringr::str_detect(string = keyword, pattern = "Inslee") ~ 5,
    stringr::str_detect(string = keyword, pattern = "Gabbard") ~ 6,
    stringr::str_detect(string = keyword, pattern = "Delaney") ~ 7,
    stringr::str_detect(string = keyword, pattern = "de Blasio") ~ 8,
    stringr::str_detect(string = keyword, pattern = "Castro") ~ 9,
    stringr::str_detect(string = keyword, pattern = "Booker") ~ 10)) %>% 
  dplyr::arrange(desc(candidate_id))


GtrendWikiIOTAirTime <- GTrendDems2020Debate01IOT %>% 
  dplyr::left_join(x = ., 
                   y = WikiDemAirTime01, 
                   by = "candidate_id")

# GtrendWikiIOTAirTime %>%
#   count(keyword, candidate) %>%
#   tidyr::spread(keyword, n)
```

Create a categorical poll percentage variable. 

```{r create-poll_perc_cat}
# poll_perc_cat -------------------------------------------------------------
GtrendWikiIOTAirTime <- GtrendWikiIOTAirTime %>% 
  dplyr::mutate(poll_perc_cat = case_when(
    stringr::str_detect(keyword, "Oâ€™Rourke") ~ "> 10.0% of voters",
    stringr::str_detect(keyword, "Warren") ~ "> 10.0% of voters",
    
    stringr::str_detect(keyword, "Booker") ~ "2-4.0% of voters",
    stringr::str_detect(keyword, "Klobuchar") ~ "2-4.0% of voters",
    stringr::str_detect(keyword, "Castro") ~ "2-4.0% of voters",


    stringr::str_detect(keyword, "Gabbard") ~ "1 - 1.3% of voters",
    stringr::str_detect(keyword, "Ryan") ~ "1 - 1.3% of voters",
    stringr::str_detect(keyword, "Inslee") ~ "1 - 1.3% of voters",
    stringr::str_detect(keyword, "de Blasio") ~ "1 - 1.3% of voters",
    stringr::str_detect(keyword, "Delaney") ~ "1 - 1.3% of voters"))
```

Turn this into a factor. 

```{r labels-factors}
# assing labels
GtrendWikiIOTAirTime <- GtrendWikiIOTAirTime %>% 
  dplyr::mutate(poll_perc_fct = factor(x = poll_perc_cat))
# check levels 
# Dems2020Debate01IOTAirTime$poll_perc_fct %>% levels()
# relvel
GtrendWikiIOTAirTime <- GtrendWikiIOTAirTime %>% 
  dplyr::mutate(poll_perc_fct = forcats::fct_relevel(.f = poll_perc_fct,
                    "> 10.0% of voters",
                    "2-4.0% of voters",
                    "1 - 1.3% of voters"))

# check levels 
GtrendWikiIOTAirTime$poll_perc_fct %>% levels()
```

Finally was can join.

```{r create-mapping-data}
# mapping data (by region) ------------------------------------------------
# convert to tibble (another data structure in R)
GtrendDems2020IBRGroup1 <- tibble::as_tibble(GTrendDems2020Night1G1$interest_by_region)
GtrendDems2020IBRGroup2 <- tibble::as_tibble(GTrendDems2020Night1G2$interest_by_region)
# bind Dems2020IBRGroup1 Dems2020IBRGroup2 together 
GtrendDems2020IBR <- bind_rows(GtrendDems2020IBRGroup1, 
                        GtrendDems2020IBRGroup2, .id = "data")
```

Next we convert the `region` variable to lowercase and join this to the `statesMap` data from `ggplot2`

```{r wrangle-GtrendDems2020InterestByRegion}
# convert the region to lowercase
GtrendDems2020InterestByRegion <- GtrendDems2020IBR %>% 
  dplyr::mutate(region = stringr::str_to_lower(location))
# create a data set for the states in the US
statesMap = ggplot2::map_data("state")
# now merge the two data sources together
GtrendDems2020InterestByRegion <- GtrendDems2020InterestByRegion %>% 
  dplyr::inner_join(x = .,
                   y = statesMap, 
                   by = "region")
```

Now we have two data sets for visualizations and maps!
